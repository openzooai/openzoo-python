{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenZoo: Getting Started\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/openzooai/openzoo-python/blob/main/demo.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Imports & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Basic Usage\n",
    "\n",
    "OpenZoo is OpenAI compatible - the only install is the OpenAI client package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just set the 'api_key' and 'base_url' parameters to the OpenZoo API key and Base URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=\"<OPENZOO_API_KEY_GOES_HERE>\",\n",
    "    base_url=\"https://api.openzoo.ai/v1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference - where you would normally specify a model, you provide a **spec**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"chat\",\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You are a helpful but brief assistant.\"},\n",
    "              {\"role\": \"user\", \"content\": \"Tell me a joke about unicorns\"}],\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "pprint(chat_completion_to_dict(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Streaming inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = client.chat.completions.create(\n",
    "    model=\"chat\",\n",
    "    messages=[{\"role\": \"system\", \"content\": \"You are a helpful but brief assistant.\"},\n",
    "              {\"role\": \"user\", \"content\": \"Tell me a joke about bunnies\"}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "chunk = None\n",
    "content = \"\"\n",
    "\n",
    "for chunk in stream:\n",
    "    content += chunk.choices[0].text\n",
    "    print(chunk.choices[0].text, end=\"\", flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk.choices[0].text = content\n",
    "chat_completion_chunk_to_dict(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Specs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"chat\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke about unicorns\"}],\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "pprint(chat_completion_to_dict(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Safety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"chat safe\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Tell me a joke about unicorns\"}],\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "pprint(chat_completion_to_dict(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"summarization XS\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"\"\"\n",
    "Urban Lab - Centre for Science and Environment Analysis\n",
    "Report 1\n",
    "Winter pollution in India: Overview of\n",
    "the crisis\n",
    "In 2020 the Urban Lab at the Centre for Science and Environment (CSE) started publishing the state of\n",
    "winter air quality among cities and towns of India that have realtime air quality monitoring. The analysis\n",
    "of the winter of 2022-23 covered 234 cities. The assessment of the seasonal trend in PM2.5\n",
    "concentration was done by sourcing realtime data from 440 CAAQMS stations via CPCBÂ´s online portal.\n",
    "A huge volume of data points have been cleaned and data gaps have been addressed based on the\n",
    "USEPA method for this analysis. Winter has been defined as 1 October to 28 February. A minimum of 90\n",
    "days of valid 24-hour values was deemed mandatory to assign a seasonal/winter PM2.5 level to a\n",
    "station. Cities with multiple stations are represented by the mean of all the city stations that meet the\n",
    "minimum data requirement for both 2021-22 winter and 2022-23 winter.\n",
    "Regional levels have been constructed using the mean of all cities with valid seasonal levels in the\n",
    "particular region. India level has been determined as the mean of regional levels. These regional and\n",
    "national levels are only indicative.\n",
    "National and regional: North India was the most polluted region despite registering an improvement of\n",
    "about 15 per cent from the previous winter. Sound India remains the least polluted region but PM2.5\n",
    "levels have risen almost 17 per cent from the previous year. Pollution rose in West India and Northeast\n",
    "India as well. Central India registered marginal improvement in its winter air quality. Overall, the national\n",
    "average air quality for the 2022-23 winter was 1.32 per cent worse compared to the previous winter (See\n",
    "Table 1R1: National and regional winter PM2.5 levels)\n",
    "\n",
    "Summarize the above text.\n",
    "\"\"\"\n",
    "}],\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "pprint(chat_completion_to_dict(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"math L\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"\"\"\n",
    "Sarah is planning her son Tom's birthday party and intends to buy 3 balloons at $0.50 each, \n",
    "2 cupcakes at $2 each, and 2 juice boxes at $1 each for each of the 10 children initially \n",
    "expected to attend. Just before the party, she finds out that 2 more children will be joining. \n",
    "Calculate the total cost Sarah will spend on balloons, cupcakes, and juice boxes for all the children. \n",
    "Assume these are the only expenses for the party.\n",
    "\"\"\"}],\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "pprint(chat_completion_to_dict(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text to Sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"code\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"\"\"\n",
    "Find the total sales amount for each product category in the last quarter, \n",
    "considering only those categories that generated more than $10,000 in sales. \n",
    "Sort the categories by their total sales amount in descending order. \n",
    "Respond with only the SQL code, nothing else.\n",
    "\"\"\"}],\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "pprint(chat_completion_to_dict(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings (no spec, directly specify the embeding model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.embeddings.create(input = [\"Some text that needs to be embedded\"], model='togethercomputer/m2-bert-80M-8k-retrieval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Inferring task type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=None,\n",
    "    messages=[{\"role\": \"user\", \"content\": \"\"\"\n",
    "Sarah is planning her son Tom's birthday party and intends to buy 3 balloons at $0.50 each, \n",
    "2 cupcakes at $2 each, and 2 juice boxes at $1 each for each of the 10 children initially \n",
    "expected to attend. Just before the party, she finds out that 2 more children will be joining. \n",
    "Calculate the total cost Sarah will spend on balloons, cupcakes, and juice boxes for all the children. \n",
    "Assume these are the only expenses for the party.\n",
    "\"\"\"}],\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "pprint(chat_completion_to_dict(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### You can specify the model when you need to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"mistralai/Mixtral-8x7B-Instruct-v0.1\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"\"\"\n",
    "You are a prompt intent classifier. Classify the following prompt according to one of these categories:\n",
    "               \n",
    "- chat\n",
    "- code\n",
    "- summarization\n",
    "- text_to_sql\n",
    "- math\n",
    "- translation\n",
    "             \n",
    "Classify the following prompt:\n",
    "               \n",
    "---               \n",
    "Find the total sales amount for each product category in the last quarter, \n",
    "considering only those categories that generated more than $10,000 in sales. \n",
    "Sort the categories by their total sales amount in descending order. \n",
    "Respond with only the SQL code, nothing else.\n",
    "---\n",
    "               \n",
    "Return only the class selected from above and nothing else.\n",
    "\"\"\"}],\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "pprint(chat_completion_to_dict(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
